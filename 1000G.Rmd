---
title: "1000 Genomes Exercises in SciDB"
output:
  html_document:
    pandoc_args: ["+RTS", "-K16g", "-RTS"]
---

```{r, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# http://stackoverflow.com/questions/1716012/stopwatch-function-in-r/1716344#1716344
tic <- function(gcFirst = TRUE, type=c("elapsed", "user.self", "sys.self"))
{
   type <- match.arg(type)
   assign(".type", type, envir=baseenv())
   if(gcFirst) gc(FALSE)
   tic <- proc.time()[type]         
   assign(".tic", tic, envir=baseenv())
   invisible(tic)
}

toc <- function()
{
   type <- get(".type", envir=baseenv())
   toc <- proc.time()[type]
   tic <- get(".tic", envir=baseenv())
   print(toc - tic)
   invisible(toc)
}
```

SciDB is a scale-out DBMS designed for scientific use cases, with built-in capabilities for sophisticated mathematical calculations beyond the typical domain of SQL/NoSQL systems. This workbook demonstrates using SciDB's R interface for scalable query and analysis of 1000 Genomes phase 3 genotype data, including simple aggregations such as computing transition/transversion ratios, and more advanced calculations such as principal component analysis and estimating linkage disequilibrium.

First, we connect to SciDB and obtain handles to the data arrays. For development/testing on a modest machine, we'll just look at chromosomes 21 and 22 across the 2,504 individuals; but SciDB can scale out on a cluster to handle arbitrarily large datasets.

```{r, warning=FALSE, error=FALSE, message=FALSE}
require(ggplot2)
require(pipeR)
require(scidb)
scidbconnect()
SAMPLE <- scidb("KG_SAMPLE")
CHROMOSOME <- scidb("KG_CHROMOSOME")
VARIANT <- merge(scidb("KG_VARIANT"), subset(CHROMOSOME, "chromosome='10' or chromosome='21' or chromosome='22'"))
VARIANT <- scidbeval(VARIANT)
GENOTYPE <- project(merge(scidb("KG_GENOTYPE"),project(VARIANT,'chromosome')),
                    c("allele_1","allele_2","phase"))
```

The `VARIANT` array for chomosomes 21 and 22 has been stored in SciDB's memory (but not the memory of our local R process) by the `scidbeval()` expression above. In contrast, the `GENOTYPE` array is merely a lazy expression, denoting but not materializing the subset of all the genotypes on chromosomes 21 and 22. Because `GENOTYPE` is our biggest array by far, we avoid copying any significant portion of it.

Let's take a look at the schema.

```{r, warning=FALSE}
head(VARIANT)
str(VARIANT)
count(VARIANT)

GENOTYPE[9,60494,60494,1,0:4][]
str(GENOTYPE)
count(GENOTYPE)
```

On the other hand, small arrays can easily be moved back and forth between SciDB and R, with one pitfall: SciDB arrays are zero-based, while R uses one-based indexing. But as genome scientists, we're right at home dealing with that!

## Transition/transversion ratio

The transition/transversion ratio (Ti/Tv) is a common quality metric for variant call sets. Let's compute Ti/Tv of all the variants with respect to the reference genome. This first calculation is on the variants only, not the individuals' genotypes, and thus involves only a modest amount of data.

```{r}
# count biallelic SNPs
SNP <- subset(VARIANT, "(reference='A' or reference='G' or reference='C' or reference='T') and
                        (alternate='A' or alternate='G' or alternate='C' or alternate='T')")
snps <- count(SNP)
snps

# annotate each SNP as to whether it's a transition (or else transversion)
transitions_filter_str <- "(reference='A' and alternate='G') or (reference='G' and alternate='A') or
                           (reference='C' and alternate='T') or (reference='T' and alternate='C')"
SNP <- bind(SNP,"is_transition",paste("bool(iif(", transitions_filter_str, ",TRUE,FALSE))"))
SNP <- scidbeval(SNP)

# count transitions
ti <- count(SNP$is_transition %==% TRUE)
ti

# count transversions
tv <- count(SNP$is_transition %==% FALSE)
tv

# report Ti/Tv
stopifnot(ti+tv == snps)
ti/tv
```

Now let's look at the distribution of Ti/Tv across the individuals in the population. We use pipeR's `%>>%` operator to express a multi-step data processing pipeline, where `f(x) %>>% g(y)` denotes `g(f(x),y)`.

```{r}
calculate.titv <- function(G) {
  (bind(G, "alt_copies", "iif(allele_1,1,0)+ iif(allele_2,1,0)")
   %>>% merge(SNP$is_transition)
   %>>% bind(c("ti", "tv"),
             c("iif(is_transition, alt_copies, 0)",
               "iif(not is_transition, alt_copies, 0)"))
   %>>% aggregate(FUN="sum(ti) as ti, sum(tv) as tv", by = "sample_id")
   %>>% scidbeval)
}
titv <- calculate.titv(GENOTYPE)[]

invisible(hist(titv$ti/titv$tv, xlab="Ti/Tv", ylab="# individuals", main=""))
```

All the data traversal is performed by SciDB in parallel; then the histogram buckets and counts are imported into R memory for plotting. Note that lazily-evaluated subexpressions can be stored, composed, and reused as R variables. This is often a lot nicer than formulating SQL!

We can also calculate Ti/Tv for just one individual, by filtering the input matrix:

```{r}
titv <- calculate.titv(merge(GENOTYPE, SAMPLE$sample %==% "HG03209"))[]
titv$ti/titv$tv
```

## Principal component analysis

Now let's find principal components of the genotype data and project the individual genomes onto them, revealing the underlying population structure. Begin by selecting common SNPs, because rare variants inherently don't contribute much to the overall variance.

Select all variants whose af is greater than min_af and less than max_af; if variant_limit is
specified, then select up to that many variants, chosen randomly. 

```{r}
#pca = function(min_af = 0.1, max_af = 0.9, variant_limit, chunk_size=512)
min_af = 0.1
max_af = 0.9
chunk_size=512
#variant_limit=100

t0=proc.time()
KG_CHROMOSOME = scidb("KG_CHROMOSOME")
KG_VARIANT    = scidb("KG_VARIANT")
KG_GENOTYPE   = scidb("KG_GENOTYPE")
KG_SAMPLE     = scidb("KG_SAMPLE")

KG_POPULATION = scidb("KG_POPULATION")
selected_variants = dimension_rename(project(unpack(subset(KG_VARIANT, sprintf("af>%f and af<%f", min_af, max_af))), c("chromosome_id, start, end, alternate_id")), old="i", new="dense_variant_id")
if (exists('variant_limit')) # (!missing(variant_limit))
{
 selected_variants = bind(selected_variants, "randomizer", "random()")
 selected_variants = sort(selected_variants, attributes="randomizer")
 selected_variants = selected_variants[between(0,variant_limit-1),]
 selected_variants = dimension_rename(selected_variants, old="n", new="dense_variant_id")
}
selected_variants = scidbeval(selected_variants, temp=TRUE)
num_variants = count(selected_variants)
num_samples = count(KG_SAMPLE)
print(sprintf("%f %f: Found %i variants that fit the criteria; running [%i x %i]", 
              (proc.time()-t0)[3], (proc.time()-t0)[3], num_variants, num_variants, num_samples))
t1=proc.time()
```
The redimension operation just removes some unneeded attributes and dimensions.

```{r}
redim_guide = redimension(selected_variants, sprintf("<dense_variant_id:int64> %s", scidb:::build_dim_schema(KG_VARIANT)))

```
<value> [sample_id, variant_number] where value is 2 if the variant is present in both alleles,
1 if the variant is present in one allele or 0 otherwise. 

```{r}
redim_matrix = bind(KG_GENOTYPE, "v", "double(iif(allele_1 and allele_2, 2.0, iif(allele_1 or allele_2, 1.0, 0.0)))")
redim_matrix = merge(redim_matrix, redim_guide)
redim_matrix = redimension(redim_matrix, sprintf("<v:double null> [sample_id = 0:%i,%i,0, dense_variant_id=0:%i,%i,0]", 
                                                 num_samples-1, chunk_size, num_variants-1, chunk_size))
redim_matrix = replaceNA(redim_matrix)
redim_matrix = scidbeval(redim_matrix, temp=TRUE)
print(sprintf("%f %f: Built matrix", (proc.time()-t0)[3], (proc.time()-t1)[3]))
t1=proc.time()

```

Sweep out the column means
```{r}
centered = sweep(redim_matrix, 2, apply(redim_matrix, 2, mean))
centered = scidbeval(centered, temp=TRUE)
print(sprintf("%f %f: Centered", (proc.time()-t0)[3], (proc.time()-t1)[3]))
t1=proc.time()

```
## Calculate covariance

Calculate and display the covariance
[Previous text]: Normalize each variable and compute the sample covariance matrix ("economy-sized", since we have many more variables than observations):
```{r}
X = centered
Y = t(X)  # samples in columns
Y = Y - apply(Y,2,mean)
CV = crossprod(Y)/(nrow(Y) - 1)
invisible(image(CV))
```
Both axes above are simply the 2,504 samples in the phase 3 data. The observed correlation structure probably just reflects how the 1000 Genomes project added sample batches of various ethnicities over time.

Now perform SVD on the covariance matrix, and plot the projection of the observations (individuals) onto the first three principal components:

```{r}
svded =  scidb(sprintf("gesvd(%s, 'left')", centered@name))
svded = scidbeval(svded, temp=TRUE)
print(sprintf("%f %f: SVD Computed", (proc.time()-t0)[3], (proc.time()-t1)[3]))

download = svded[,0:2][]

```
Make a cute 3D plot.
The plot uses https://github.com/bwlewis/rthreejs

```{r}
color = iqdf(project(bind(merge(KG_SAMPLE, KG_POPULATION), "color", "iif(population='AMR', 'blue', iif(population='AFR', 'red', iif(population='EUR', 'green', iif(population='EAS', 'purple', 'orange'))))"), "color"), n=Inf)$color

#See https://github.com/bwlewis/rthreejs
library(threejs)
scatterplot3js(download, size=0.5, color=color)

```

For the avoidance of doubt: all the matrix calculations here were parallelized in SciDB, not computed by the local R process. We didn't have to dump a lot of data into any separate system for numerical analysis.

[Previous text]: Now construct a matrix `G` where `G[i,j]` is the number of copies of the alt allele found in sample `i`, common SNP `j`. The samples are observations, and the SNPs are variables. Reference: doi:10.1371/journal.pgen.0020190

The PCA's interpretation becomes clear if we label the points by the ethnicity of each individual. This also provides an elementary example of joining "phenotypic data":

```{r, warning=FALSE}
H = download
pd <- data.frame(PC1=H[,1], PC2=H[,2], PC3=H[,3],
                 population=scidb("KG_POPULATION")$population[][,3])

popnames <- list(
  ACB='Caribbean', ASW='African-Amer', BEB='South Asian', CEU='European',
  CHB='East Asian', CDX='East Asian', CHS='East Asian', CLM='Central Amer',
  ESN='African', FIN='European', GBR='European', GIH='South Asian',
  GWD='African', IBS='European', ITU='South Asian', JPT='East Asian',
  KHV='East Asian', LWK='African', MSL='African', MXL='Central Amer',
  PEL='South Amer', PJL='South Asian', PUR='Caribbean', STU='South Asian',
  TSI='European', YRI='African'
)
for (i in 1:length(popnames)) {
  levels(pd$population)[levels(pd$population) == names(popnames)[i]] <- popnames[[names(popnames)[i]]]
}

cbbPalette <- c("#E69F00", "#CC79A7", "#D55E00", "#56B4E9",
                "#009E73", "#999999", "#0072B2", "#FF0000")

ggplot(pd, aes(PC1,PC2,shape=population,color=population)) + geom_point() + scale_shape_manual(values=(1:nrow(pd))+1) + scale_color_manual(values=cbbPalette) + theme(panel.background=element_blank(), legend.text=element_text(size=10))

ggplot(pd, aes(PC2,PC3,shape=population,color=population)) + geom_point() + scale_shape_manual(values=(1:nrow(pd))+1) + scale_color_manual(values=cbbPalette) + theme(panel.background=element_blank(), legend.text=element_text(size=10))
```

In addition to generating cool visualizations, PCA plays a crucial role in statistically correcting for population stratification in large-scale genetic association studies.

## Linkage disequilibrium

Linkage disequilibrum (LD) describes the correlation among the alleles observed at nearby sites. It reflects the inheritance of haplotypes on short timescales compared to the rate of genetic recombination. Let's look at LD among common SNPs in a region of several hundred kilobases.

<To be added>
